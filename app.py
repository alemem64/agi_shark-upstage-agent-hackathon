import streamlit as st
from page.portfolio import show_portfolio
from page.api_setting import show_api_settings, init_api_session_state
from model.api_anthropic import stream_anthropic_response

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
init_api_session_state()

# ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
if 'messages' not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! íˆ¬ìì— ê´€í•´ ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}]

st.set_page_config(
    page_title="AI íˆ¬ì ì±„íŒ…ë´‡",
    page_icon="ğŸ¦ˆ",
    layout="wide",
)

main_col, chat_col = st.columns([0.65, 0.35], gap="large")

with main_col:
    portfolio_tab, strategy_tab, api_tab = st.tabs(["í¬íŠ¸í´ë¦¬ì˜¤", "ê±°ë˜ ë‚´ì—­", "íˆ¬ì ì „ëµ", "API ì„¤ì •"])

    with portfolio_tab:
        show_portfolio()

    with strategy_tab:
        st.title("íˆ¬ì ì „ëµ")
        st.write("This is the strategy page of the app.")

    with api_tab:
        show_api_settings()


with chat_col:
    model_options = st.selectbox("ëª¨ë¸ ì„ íƒ", ("claude 3.7 sonnet", "claude 3 haiku"))

    chat_container = st.container(height=700, border=True)
    
    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ (ì±„íŒ… ì»¨í…Œì´ë„ˆ ì•„ë˜ì— ë°°ì¹˜)
    user_prompt = st.chat_input(
        placeholder="ì–´ë–»ê²Œ íˆ¬ìí• ê¹Œìš”?",
        accept_file=True,
        file_type=None
    )


    # ì±„íŒ… ê¸°ë¡ ì±„ìš°ê¸° 
    with chat_container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.write(message["content"])
    
    if user_prompt:
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ ë° í‘œì‹œ

        user_prompt_text = user_prompt.text if user_prompt.text else ""
        user_prompt_file = user_prompt["files"] if user_prompt["files"] else None
        
        st.session_state.messages.append({"role": "user", "content": user_prompt_text})


        # ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
        with chat_container:
            with st.chat_message("user"):
                st.write(user_prompt_text)
                
            with st.chat_message("assistant"):
                response_placeholder = st.empty()
                full_response = ""
                
                # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
                for chunk in stream_anthropic_response(
                    user_prompt_text,
                    model_options
                ):
                    full_response += chunk
                    response_placeholder.markdown(full_response + "â–Œ")
                
                # ìµœì¢… ì‘ë‹µìœ¼ë¡œ ì—…ë°ì´íŠ¸
                response_placeholder.markdown(full_response)
                
                # ì‘ë‹µ ê¸°ë¡ì— ì €ì¥
                st.session_state.messages.append({"role": "assistant", "content": full_response})



